{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o_eISXMq5W0H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import dask.dataframe as dd\n",
        "import dask.array as da\n",
        "from dask.distributed import Client\n",
        "from dask_ml.metrics import accuracy_score\n",
        "from dask_ml.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uflPc_Af3zRA"
      },
      "outputs": [],
      "source": [
        "# Main class for layer\n",
        "class Layer:\n",
        "    def __init__(self):\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "    def forward(self, input):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(self, up_gradient):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def step(self, learning_rate):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PLx6ZH-16m_n"
      },
      "outputs": [],
      "source": [
        "# Loss function class\n",
        "class Loss:\n",
        "    def __init__(self):\n",
        "        self.prediction = None\n",
        "        self.target = None\n",
        "        self.loss = None\n",
        "\n",
        "    def __call__(self, prediction, target):\n",
        "        return self.forward(prediction, target)\n",
        "\n",
        "    def forward(self, prediction, target):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(self):\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9WQLMUMO74pY"
      },
      "outputs": [],
      "source": [
        "# Multi-Layer Perceptron (MLP)\n",
        "class MLP:\n",
        "    def __init__(self, layers, loss, learning_rate):\n",
        "        self.layers = layers\n",
        "        self.loss_fn = loss\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def __call__(self, input):\n",
        "        return self.forward(input)\n",
        "\n",
        "    def forward(self, input):\n",
        "        for layer in self.layers:\n",
        "            input = layer(input)\n",
        "        return input\n",
        "\n",
        "    def backward(self):\n",
        "        up_gradient = self.loss_fn.backward()\n",
        "        for layer in reversed(self.layers):\n",
        "            up_gradient = layer.backward(up_gradient)\n",
        "\n",
        "    def loss(self, prediction, target):\n",
        "        return self.loss_fn(prediction, target)\n",
        "\n",
        "    def update(self):\n",
        "        for layer in self.layers:\n",
        "            layer.step(self.learning_rate)\n",
        "\n",
        "    def train(self, x_train, y_train, epochs, batch_size):\n",
        "        losses = []\n",
        "        for epoch in tqdm(range(epochs), desc=\"Training Progress\"):\n",
        "            running_loss = 0\n",
        "            for i in range(0, x_train.shape[0], batch_size):\n",
        "                x_batch = x_train[i : i + batch_size]\n",
        "                y_batch = y_train[i : i + batch_size]\n",
        "\n",
        "                prediction = self.forward(x_batch)\n",
        "\n",
        "                # Compute Loss and ensure computation\n",
        "                loss = self.loss_fn(prediction, y_batch).mean().compute()\n",
        "                running_loss += loss\n",
        "\n",
        "                self.backward()\n",
        "                self.update()\n",
        "\n",
        "            running_loss /= (x_train.shape[0] / batch_size)\n",
        "            losses.append(running_loss)\n",
        "            print(f\"Epoch {epoch+1}/{epochs} | Loss: {running_loss:.4f}\")\n",
        "\n",
        "        return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hpi14GEY4-v2"
      },
      "outputs": [],
      "source": [
        "# Linear layer\n",
        "class Linear(Layer):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        self.w = 0.1 * da.random.normal(size=(input_size, output_size), chunks=(input_size, output_size))\n",
        "        self.b = da.zeros((1, output_size), chunks=(1, output_size))\n",
        "        self.dw = da.zeros_like(self.w)\n",
        "        self.db = da.zeros_like(self.b)\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return da.dot(self.input, self.w) + self.b\n",
        "\n",
        "    def backward(self, up_gradient):\n",
        "        self.dw = da.dot(self.input.T, up_gradient)\n",
        "        self.db = da.sum(up_gradient, axis=0, keepdims=True)\n",
        "        return da.dot(up_gradient, self.w.T)\n",
        "\n",
        "    def step(self, learning_rate):\n",
        "        self.w -= learning_rate * self.dw\n",
        "        self.b -= learning_rate * self.db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_08Z8D2-5PPE"
      },
      "outputs": [],
      "source": [
        "# ReLU activation function\n",
        "class ReLU(Layer):\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return da.maximum(0, input)\n",
        "\n",
        "    def backward(self, up_gradient):\n",
        "        return up_gradient * (self.input > 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "18JcX8uf7HTa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# CrossEntropy loss\n",
        "class CrossEntropy(Loss):\n",
        "    def forward(self, prediction, target):\n",
        "        exp_pred = da.exp(prediction - da.max(prediction, axis=1, keepdims=True))\n",
        "        self.softmax = exp_pred / da.sum(exp_pred, axis=1, keepdims=True)\n",
        "        self.target = target\n",
        "        return -da.mean(da.sum(target * da.log(self.softmax + 1e-15), axis=1))\n",
        "\n",
        "    def backward(self):\n",
        "        return (self.softmax - self.target) / self.target.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UaeXkZeA7hc-"
      },
      "outputs": [],
      "source": [
        "# Mean Squared Error loss\n",
        "class MSE(Loss):\n",
        "    def forward(self, prediction, target):\n",
        "        self.prediction = prediction\n",
        "        self.target = target\n",
        "        return da.mean((prediction - target) ** 2)\n",
        "\n",
        "    def backward(self):\n",
        "        return 2 * (self.prediction - self.target) / len(self.target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2.3\n"
          ]
        }
      ],
      "source": [
        "print(pd.__version__)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "80S6_V2bF7RY"
      },
      "outputs": [],
      "source": [
        "# Simulate data using Dask directly for faster loading\n",
        "def simulate_data():\n",
        "    client = Client()  # Start Dask client\n",
        "\n",
        "    n_samples = 500000\n",
        "    n_features = 100\n",
        "\n",
        "    # Generate data directly as Dask arrays\n",
        "    X = da.random.random((n_samples, n_features), chunks=(100_000, n_features))\n",
        "    y = da.random.randint(0, 2, size=(n_samples,), chunks=(100_000,))\n",
        "\n",
        "    # Convert to Dask DataFrame\n",
        "    X_dd = dd.from_dask_array(X, columns=[f'feature{i}' for i in range(n_features)])\n",
        "    y_dd = dd.from_dask_array(y, columns=['target'])\n",
        "\n",
        "    # Split into training & test sets (85% train, 15% test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_dd, y_dd, test_size=0.15, random_state=42)\n",
        "\n",
        "    # Convert back to Dask arrays\n",
        "    return X_train.to_dask_array(lengths=True), X_test.to_dask_array(lengths=True), \\\n",
        "           y_train.to_dask_array(lengths=True), y_test.to_dask_array(lengths=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4ab3EwyEfwT",
        "outputId": "dbbaf728-dc79-40a1-c5ac-ff6086fc2e3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/dask_ml/model_selection/_split.py:464: FutureWarning: The default value for 'shuffle' must be specified when splitting DataFrames. In the future DataFrames will automatically be shuffled within blocks prior to splitting. Specify 'shuffle=True' to adopt the future behavior now, or 'shuffle=False' to retain the previous behavior.\n",
            "  warnings.warn(\n",
            "Training Progress:   0%|          | 0/30 [40:12<?, ?it/s]Task exception was never retrieved\n",
            "future: <Task finished name='Task-1239794' coro=<Client._gather.<locals>.wait() done, defined at /opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/client.py:2394> exception=AllExit()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/client.py\", line 2403, in wait\n",
            "    raise AllExit()\n",
            "distributed.client.AllExit\n",
            "\n",
            "2025-02-26 23:27:19,964 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53190' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('getitem-bd020231c39eff311808ec8afaa1bf71', 0, 0), ('getitem-17851cb05fa02af1755b2bf297aa0770', 0, 0), ('getitem-f00aa260f6be568a2630f77f1c444566', 0, 0), ('getitem-4ad1c38123af3f3a866dfd14fc447e86', 0, 0), ('getitem-e9aa137eb0cafffa8c79b0c28846026e', 0, 0), ('getitem-b61e7bfd1586105472be2596dcef2d2f', 0, 0), ('getitem-58a00d5520646b9ac937fd48ea369a09', 0, 0), ('getitem-8e4969af75c5a357632256bd7aaec5a9', 0, 0), ('getitem-aeef9ab23f48d7d22993bb5a03ab1e50', 0, 0), ('getitem-fac28dd4d84e35f6221dc2f66bbab3ae', 0, 0), ('getitem-43947f3b1e4cfa57f8feca6eb2c24a42', 0, 0), ('getitem-74789891d0a98a6522ef999b13fd0ae8', 0, 0), ('getitem-e8f82b2a316cc0f4a76d0492cddeb29e', 0, 0), ('getitem-f1716e89399bdc3ac962ef981fd636a3', 0, 0), ('getitem-afa3d2ce134916eea80cc08be3d5344f', 0, 0), ('getitem-675b9390c1a26cabdb05e77292832c92', 0, 0), ('getitem-7abd0c4dedd4a40e072eab688b7c5603', 0, 0), ('getitem-0c7d0237fccf46b1a39afa420851a821', 0, 0), ('getitem-2bef087bd43cb515391eee5e49bfbaba', 0, 0), ('getitem-022406b6ad7675c2a7c12003cc5a7f0e', 0, 0), ('getitem-84b367a8adc0516a4115020891f4f8b3', 0, 0), ('getitem-6174e7838563ad2ef4ffbf7a423e3190', 0, 0), ('getitem-7d05967451de7f8190fd5561a735bbbb', 0, 0), ('getitem-7ce7ccc08fdaa178641cb14779d5ec65', 0, 0), ('getitem-913891aac15f51fa34f28950879bd085', 0, 0), ('getitem-2802cce0af7e367d5cf22a6f5ed1e5bb', 0, 0), ('getitem-43037658653cafee0fcaf87cce8968f6', 0, 0), ('getitem-ada730a2086720488603d35b8933c163', 0, 0), ('getitem-7fb2eb193db0a6e5fbf0d3837850ec16', 0, 0), ('getitem-2fb7b9362f1828f85811cc2a28336bee', 0, 0), ('getitem-0ae7d34e4fc95c538fa75dac561da58d', 0, 0), ('getitem-bd020231c39eff311808ec8afaa1bf71', 1, 0), ('getitem-61a145fd7d544d6e838bbe53869448e4', 0, 0), ('getitem-2d9d9ee6c042171964db33c016f81400', 0, 0), ('getitem-5984fc317424e5d9f80ba07a167d6133', 0, 0), ('getitem-ee21c72f864722204703c0a4eb2f7a72', 0, 0), ('getitem-cdc022c49678b75d6f5f5157f3a24cd3', 0, 0), ('getitem-1594039ee2cb28bd470ff5ac8ea5e9d6', 0, 0), ('getitem-7a82ddc2bd43dce6703460e18fde7a23', 0, 0), ('getitem-84884903a5457898e171f9ae598d9054', 0, 0), ('getitem-31989b1931bf3f12350064cef16013d5', 0, 0), ('getitem-e396615c3c862ce9b7d9cef0bfda830a', 0, 0), ('getitem-31fc5d5610bfdbbcaf2ed793c42f4176', 0, 0), ('getitem-010b4551d09c9266bb66bb93cec5b3ea', 0, 0), ('getitem-d3741871e668496137f3594cdb9ce513', 0, 0), ('getitem-f457476d802d932a85dd9544d109d7c4', 0, 0), ('getitem-716fc183acce93b85bd3ddefb70c1e90', 0, 0), ('getitem-8aefbbffa52e898efe05b53c9cf710fd', 0, 0), ('getitem-51d87d7752900d51f4f8e569b5a59fc3', 0, 0), ('getitem-54e0b13ce0f755fd66d4075840318ba1', 0, 0), ('getitem-b01a768cf394d6a535c8d7d0ea1c9af7', 0, 0), ('getitem-1443e2a824bafbd20259e5a8172e8d04', 0, 0), ('getitem-d7f11b8f9ceae12f7acac9c9aebb2548', 0, 0), ('getitem-511d2dd67f3b04da073a7a64552bcb0f', 0, 0), ('getitem-e98d4c6388592d77b339984a2419118c', 0, 0), ('getitem-ec0f86cb30a44925b7ed378a147a3c51', 0, 0), ('getitem-7d264e3c8541fcabb1993c5c391fb108', 0, 0), ('getitem-7a956cc3954663be62e5b702812d4e2f', 0, 0), ('getitem-2e8b7aacaf3cc063852badd686f80b7f', 0, 0), ('getitem-c2a63787687a586dcf33c5c840bc6772', 0, 0), ('getitem-f424a5f0dac88b7c8d0b93398d02c81e', 0, 0), ('getitem-537a271892cd8c30602a99ca70654267', 0, 0), ('getitem-af4d39c7349fd5b2f7594b30f340959c', 0, 0), ('getitem-3578911d68e3c00aa0f2f931cdb1e486', 0, 0), ('getitem-763ddbbb39980d7ed2435ad65dd4a50a', 0, 0), ('getitem-f03946cc8dac4e0d3e8f1539155d9a52', 0, 0), ('getitem-721d371e988193594238b7f8d106c767', 0, 0)} (stimulus_id='handle-worker-cleanup-1740630439.9643369')\n",
            "2025-02-26 23:27:19,969 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53183' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('getitem-8a4ea72ad52e42b3c3de65c023e58dc6', 0, 0), ('getitem-a4ef59b84086ea5f39df9877937d12e5', 0, 0), ('getitem-21b404aeab48a38a384d279038c23b96', 0, 0), ('getitem-ae27cb8a0de5a2772cdd4810ebfc2421', 0, 0), ('getitem-0e942ecdcd335254a00d20ec806b32f7', 0, 0), ('getitem-0ebb90f1ce03ff1974b2032d1a0d9399', 0, 0), ('getitem-4c0aa424c090bd87ff6478501964af2d', 0, 0), ('getitem-4d423c6a794b5b791a6c1808f7565e78', 0, 0), ('getitem-b420b7f9099878f3dde61014df29a904', 0, 0), ('getitem-5e73d6a70ff22a4392fb3c8a03a62cd2', 0, 0), ('getitem-f5ab2d75db4d39eeb661f3cd7898ca14', 0, 0), ('getitem-3c1e9b8c9ef3ecc00bc5788ecd0c5714', 0, 0), ('getitem-65c5f05d28c95634758a2fbba24d5dad', 0, 0), ('getitem-bf3fa5b47b5b859c8c1a88f5b412b852', 0, 0), ('getitem-f9604f9addfd3bc509774d981a81d3a5', 0, 0), ('getitem-288d5c25a9fccda4450f42f3e4016af2', 0, 0), ('getitem-df56b70b8a08a0731693d2af9377e117', 0, 0), ('getitem-c51b47e0bd47a532221b5a933da72ca0', 0, 0), ('getitem-6d662eaf5fba65b4b5a2237679a2e954', 0, 0), ('getitem-c7cabee517ac06c2731b83ae9898f891', 0, 0), ('getitem-afd9a18b29af44c838b3e5ea40a7bfc3', 0, 0), ('getitem-2b5e104296410c544680ca61c00056b9', 0, 0), ('getitem-5170e4a5b16ec195c8b73c884671e955', 0, 0), ('getitem-89326802ab29c3e4b9d7c9e26d1effc9', 0, 0), ('getitem-2e2b972f05685a0b3de6c838a0ee5764', 0, 0), ('getitem-10d013fa908187c34bb3f06d26e23704', 0, 0), ('getitem-9f0c8aad35f45cb2de62b8ae64e99bf0', 1, 0), ('getitem-f32485ee2c1d97d6a5d8dace61f8c1fa', 0, 0), ('getitem-ee17aa8e2705a22c2590302d96a618e0', 0, 0), ('getitem-176f66b502e77486a304ff385dabb138', 0, 0), ('getitem-1b3d87bfdf03ee12738746369f9f98dd', 0, 0), ('getitem-42908f1b0c060cab8e195268cbb64415', 0, 0), ('getitem-9b913379cd20f28b7b1831ec142b20cb', 0, 0), ('getitem-148756189118ee53f48f335f16261298', 0, 0)} (stimulus_id='handle-worker-cleanup-1740630439.96914')\n",
            "2025-02-26 23:27:19,971 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53184' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('getitem-5a5a3d9bce3588e8c62736c897489fea', 0, 0), ('add-62a4b612260062c062ee36dc58c8d8db', 0, 0), ('getitem-be205daecaf6ffc015619bde7bde3711', 0, 0), ('getitem-9f0c8aad35f45cb2de62b8ae64e99bf0', 0, 0), ('getitem-381f80f01ef5d5cfb71e75668c5ce43e', 0, 0), ('maximum-cb4a8bcfbdbcef609fed3108bdd2aa3a', 0, 0), ('getitem-b5097af18bf4e621978725ab49ff2f5c', 0, 0), ('getitem-446b8d41486e0b08ee08e892c47619c9', 0, 0), ('getitem-b71cb561dc818b596f4e9c02c42d5238', 0, 0), ('getitem-16eef238334897a4e618547b5c5076c7', 0, 0), ('getitem-a7ad6d27bb32088fad1c1c28fd4167c3', 0, 0), ('getitem-c106da8be9d085ddc76fd0e383e2d5fb', 0, 0), ('getitem-3ceaff766efc4c5527fcdee813c8254e', 0, 0), ('getitem-c904b575972da637954cc3c4ff26ce3a', 0, 0), ('getitem-ad23868bda02bdb6f35055a18cc21c78', 0, 0), ('getitem-af4e0d87ac9810760ad16e37b4646091', 0, 0), ('sub-23a8735cb3237597cc76cfc1c50cf46b', 0, 0), ('getitem-b6e8d499f6b7836cdbb431d554a09970', 0, 0), ('truediv-ef67453cdbcf06f29f19a028bd085188', 0, 0), ('getitem-936a05b25c85bd4d4ba440f52fafc103', 0, 0), ('getitem-a7fa232a45321690fa0826f97f2196cf', 0, 0), ('sub-e01890fb908c9aa22929fdb8f7f94951', 0, 0), ('getitem-f183becebd7f617e485debfa93819111', 0, 0), ('getitem-52f4a10fe38027079e19a2fab0c79fcd', 0, 0), ('getitem-f473c3d70f7af68cd976e5685fd6b7bf', 0, 0), ('getitem-d051650c930673ec34b2bdf347c9e978', 0, 0), ('getitem-4930dbdcd45b54ad72032c765d4e061f', 0, 0), ('getitem-77ee7f28b8485b165b2c35f615e614a6', 0, 0), ('getitem-71f11454d7f89a8c90efe5b40f32caaa', 0, 0), ('sub-3c0a5a5cc08a4556a4288c789e626481', 0, 0), ('getitem-d35d836343310ef2a1df724c251564a0', 0, 0), ('getitem-03a99fd557cfcad09679df8d937c0449', 0, 0), ('getitem-74b582d8de0a8b7be329c2dd0a6553f2', 0, 0), ('getitem-07767bcc243f9dc7a9acbe987101f0d9', 0, 0), ('getitem-4c79de3ad4e0c510b60cdf7d992ad5dc', 0, 0), ('getitem-7a07cbf51ebdd7d79d862f0256996f1e', 0, 0), ('getitem-06d878a16c59b392247fe041ed4c082f', 0, 0), ('getitem-8ddaf60eaaf097f598e18d1f142f2199', 0, 0), ('getitem-bbf3c4571e0a494e702027c81cc44ae3', 0, 0), ('getitem-8eeb7f74f684650d486c8565948bc200', 0, 0)} (stimulus_id='handle-worker-cleanup-1740630439.9711459')\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m MLP(layers, CrossEntropy(), learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m losses \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain(x_train\u001b[38;5;241m=\u001b[39mx_train, y_train\u001b[38;5;241m=\u001b[39my_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Compute accuracy\u001b[39;00m\n\u001b[1;32m     18\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(x_test)\u001b[38;5;241m.\u001b[39mcompute()\n",
            "Cell \u001b[0;32mIn[4], line 39\u001b[0m, in \u001b[0;36mMLP.train\u001b[0;34m(self, x_train, y_train, epochs, batch_size)\u001b[0m\n\u001b[1;32m     36\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x_batch)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Compute Loss and ensure computation\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(prediction, y_batch)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m     40\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/dask/base.py:374\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m compute(\u001b[38;5;28mself\u001b[39m, traverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/dask/base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mTrue\u001b[39;00m, timeout)\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-26 23:27:21,950 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
            "Process Dask Worker process (from Nanny):\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/base_events.py\", line 685, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
            "    await worker.finished()\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
            "    await self._event_finished.wait()\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
            "    await fut\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
            "    target(*args, **kwargs)\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
            "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/runners.py\", line 194, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
            "    raise KeyboardInterrupt()\n",
            "KeyboardInterrupt\n",
            "2025-02-26 23:27:21,968 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
            "2025-02-26 23:27:21,969 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
            "Process Dask Worker process (from Nanny):\n",
            "Process Dask Worker process (from Nanny):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "2025-02-26 23:27:21,970 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
            "Process Dask Worker process (from Nanny):\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/base_events.py\", line 685, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
            "    await worker.finished()\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
            "    await self._event_finished.wait()\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
            "    await fut\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/base_events.py\", line 685, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
            "    await worker.finished()\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
            "    await self._event_finished.wait()\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
            "    await fut\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
            "    target(*args, **kwargs)\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
            "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/runners.py\", line 194, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
            "    raise KeyboardInterrupt()\n",
            "KeyboardInterrupt\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
            "    target(*args, **kwargs)\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
            "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/runners.py\", line 194, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
            "    raise KeyboardInterrupt()\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/base_events.py\", line 685, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
            "    await worker.finished()\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
            "    await self._event_finished.wait()\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
            "    await fut\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
            "    target(*args, **kwargs)\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
            "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/runners.py\", line 194, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
            "    raise KeyboardInterrupt()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "# Create network layers (2-layer neural network)\n",
        "layers = [\n",
        "    Linear(100, 50),\n",
        "    ReLU(),\n",
        "    Linear(50, 2)\n",
        "]\n",
        "\n",
        "# Load data\n",
        "x_train, x_test, y_train, y_test = simulate_data()\n",
        "\n",
        "# Create the model\n",
        "model = MLP(layers, CrossEntropy(), learning_rate=0.01)\n",
        "\n",
        "# Train the model\n",
        "losses = model.train(x_train=x_train, y_train=y_train, epochs=30, batch_size=1000)\n",
        "\n",
        "# Compute accuracy\n",
        "y_pred = model(x_test).compute()\n",
        "accuracy = accuracy_score(y_test.compute(), np.argmax(y_pred, axis=1))\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Plot losses\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss Curve\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "datascience",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
